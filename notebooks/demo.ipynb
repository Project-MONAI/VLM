{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use HuggingFace model in the VILA-M3 workflow\n",
    "\n",
    "## Download the models and VLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the pretrained model\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "local_dir = snapshot_download(\n",
    "    repo_id=\"MONAI/VISTA3D-HF\",\n",
    "    local_dir=\".\",\n",
    ")\n",
    "\n",
    "\n",
    "m3_model_dir = snapshot_download(\n",
    "    repo_id=\"MONAI/Llama3-VILA-M3-8B\",\n",
    "    local_dir=\"./vila_m3_8b\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and cache images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 75/75 [00:00<00:00, 87771.43it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from agent_utils import ImageCache\n",
    "\n",
    "LIVER_URL = \"https://developer.download.nvidia.com/assets/Clara/monai/samples/ct_liver_0.nii.gz\"\n",
    "\n",
    "cache_dir = \"../data\"\n",
    "cache_images = ImageCache(cache_dir)\n",
    "\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "cache_images.cache({\"Sample 1\": LIVER_URL})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the expert VISTA-3D model using the HuggingFace pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from shutil import move\n",
    "from uuid import uuid4\n",
    "import tempfile\n",
    "import re\n",
    "import requests\n",
    "from agent_utils import get_monai_transforms, get_slice_filenames, SEGMENTATION_TOKEN\n",
    "from hugging_face_pipeline import HuggingFacePipelineHelper\n",
    "import torch\n",
    "\n",
    "\n",
    "class ExpertVista3DHF():\n",
    "    \"\"\"Expert model for VISTA-3D.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"Initialize the VISTA-3D expert model.\"\"\"\n",
    "        self.model_name = \"VISTA3D\"\n",
    "        self.pipeline = HuggingFacePipelineHelper(\"vista3d\").init_pipeline(\n",
    "            \"vista3d_pretrained_model\",\n",
    "            device=torch.device(\"cuda:0\"),\n",
    "        )\n",
    "\n",
    "    def _get_label_groups(self):\n",
    "        \"\"\"Get the label groups from the label groups path.\"\"\"\n",
    "        return {\n",
    "            \"everything\": \"../experts/vista3d/label_dict.json\",\n",
    "            \"hepatic tumor\": {\n",
    "                \"liver\": 1,\n",
    "                \"hepatic tumor\": 26\n",
    "            },\n",
    "            \"hepatoma\": {\n",
    "                \"liver\": 1,\n",
    "                \"hepatic tumor\": 26\n",
    "            },\n",
    "            \"pancreatic tumor\": {\n",
    "                \"pancreas\": 4,\n",
    "                \"pancreatic tumor\": 24\n",
    "            },\n",
    "            \"lung tumor\": {\n",
    "                \"lung\": 20,\n",
    "                \"lung tumor\": 23,\n",
    "                \"left lung upper lobe\": 28,\n",
    "                \"left lung lower lobe\": 29,\n",
    "                \"right lung upper lobe\": 30,\n",
    "                \"right lung middle lobe\": 31,\n",
    "                \"right lung lower lobe\": 32\n",
    "            },\n",
    "            \"bone lesion\": {\n",
    "                \"bone lesion\": 128\n",
    "            },\n",
    "            \"organs\": {\n",
    "                \"liver\": 1,\n",
    "                \"kidney\": 2,\n",
    "                \"spleen\": 3,\n",
    "                \"pancreas\": 4,\n",
    "                \"right kidney\": 5,\n",
    "                \"right adrenal gland\": 8,\n",
    "                \"left adrenal gland\": 9,\n",
    "                \"gallbladder\": 10,\n",
    "                \"left kidney\": 14,\n",
    "                \"brain\": 22,\n",
    "                \"lung tumor\": 23,\n",
    "                \"pancreatic tumor\": 24,\n",
    "                \"hepatic vessel\": 25,\n",
    "                \"hepatic tumor\": 26,\n",
    "                \"colon cancer primaries\": 27,\n",
    "                \"left lung upper lobe\": 28,\n",
    "                \"left lung lower lobe\": 29,\n",
    "                \"right lung upper lobe\": 30,\n",
    "                \"right lung middle lobe\": 31,\n",
    "                \"right lung lower lobe\": 32,\n",
    "                \"trachea\": 57,\n",
    "                \"left kidney cyst\": 116,\n",
    "                \"right kidney cyst\": 117,\n",
    "                \"prostate\": 118,\n",
    "                \"spinal cord\": 121,\n",
    "                \"thyroid gland\": 126,\n",
    "                \"airway\": 132\n",
    "            },\n",
    "            \"cardiovascular\": {\n",
    "                \"aorta\": 6,\n",
    "                \"inferior vena cava\": 7,\n",
    "                \"portal vein and splenic vein\": 17,\n",
    "                \"left iliac artery\": 58,\n",
    "                \"right iliac artery\": 59,\n",
    "                \"left iliac vena\": 60,\n",
    "                \"right iliac vena\": 61,\n",
    "                \"left atrial appendage\": 108,\n",
    "                \"brachiocephalic trunk\": 109,\n",
    "                \"left brachiocephalic vein\": 110,\n",
    "                \"right brachiocephalic vein\": 111,\n",
    "                \"left common carotid artery\": 112,\n",
    "                \"right common carotid artery\": 113,\n",
    "                \"heart\": 115,\n",
    "                \"pulmonary vein\": 119,\n",
    "                \"left subclavian artery\": 123,\n",
    "                \"right subclavian artery\": 124,\n",
    "                \"superior vena cava\": 125\n",
    "            },\n",
    "            \"gastrointestinal\": {\n",
    "                \"esophagus\": 11,\n",
    "                \"stomach\": 12,\n",
    "                \"duodenum\": 13,\n",
    "                \"bladder\": 15,\n",
    "                \"small bowel\": 19,\n",
    "                \"colon\": 62\n",
    "            },\n",
    "            \"skeleton\": {\n",
    "                \"bone\": 21,\n",
    "                \"vertebrae L5\": 33,\n",
    "                \"vertebrae L4\": 34,\n",
    "                \"vertebrae L3\": 35,\n",
    "                \"vertebrae L2\": 36,\n",
    "                \"vertebrae L1\": 37,\n",
    "                \"vertebrae T12\": 38,\n",
    "                \"vertebrae T11\": 39,\n",
    "                \"vertebrae T10\": 40,\n",
    "                \"vertebrae T9\": 41,\n",
    "                \"vertebrae T8\": 42,\n",
    "                \"vertebrae T7\": 43,\n",
    "                \"vertebrae T6\": 44,\n",
    "                \"vertebrae T5\": 45,\n",
    "                \"vertebrae T4\": 46,\n",
    "                \"vertebrae T3\": 47,\n",
    "                \"vertebrae T2\": 48,\n",
    "                \"vertebrae T1\": 49,\n",
    "                \"vertebrae C7\": 50,\n",
    "                \"vertebrae C6\": 51,\n",
    "                \"vertebrae C5\": 52,\n",
    "                \"vertebrae C4\": 53,\n",
    "                \"vertebrae C3\": 54,\n",
    "                \"vertebrae C2\": 55,\n",
    "                \"vertebrae C1\": 56,\n",
    "                \"skull\": 120,\n",
    "                \"sternum\": 122,\n",
    "                \"vertebrae S1\": 127,\n",
    "                \"bone lesion\": 128,\n",
    "                \"left rib 1\": 63,\n",
    "                \"left rib 2\": 64,\n",
    "                \"left rib 3\": 65,\n",
    "                \"left rib 4\": 66,\n",
    "                \"left rib 5\": 67,\n",
    "                \"left rib 6\": 68,\n",
    "                \"left rib 7\": 69,\n",
    "                \"left rib 8\": 70,\n",
    "                \"left rib 9\": 71,\n",
    "                \"left rib 10\": 72,\n",
    "                \"left rib 11\": 73,\n",
    "                \"left rib 12\": 74,\n",
    "                \"right rib 1\": 75,\n",
    "                \"right rib 2\": 76,\n",
    "                \"right rib 3\": 77,\n",
    "                \"right rib 4\": 78,\n",
    "                \"right rib 5\": 79,\n",
    "                \"right rib 6\": 80,\n",
    "                \"right rib 7\": 81,\n",
    "                \"right rib 8\": 82,\n",
    "                \"right rib 9\": 83,\n",
    "                \"right rib 10\": 84,\n",
    "                \"right rib 11\": 85,\n",
    "                \"right rib 12\": 86,\n",
    "                \"left humerus\": 87,\n",
    "                \"right humerus\": 88,\n",
    "                \"left scapula\": 89,\n",
    "                \"right scapula\": 90,\n",
    "                \"left clavicula\": 91,\n",
    "                \"right clavicula\": 92,\n",
    "                \"left femur\": 93,\n",
    "                \"right femur\": 94,\n",
    "                \"left hip\": 95,\n",
    "                \"right hip\": 96,\n",
    "                \"sacrum\": 97,\n",
    "                \"costal cartilages\": 114\n",
    "            },\n",
    "            \"muscles\": {\n",
    "                \"left gluteus maximus\": 98,\n",
    "                \"right gluteus maximus\": 99,\n",
    "                \"left gluteus medius\": 100,\n",
    "                \"right gluteus medius\": 101,\n",
    "                \"left gluteus minimus\": 102,\n",
    "                \"right gluteus minimus\": 103,\n",
    "                \"left autochthon\": 104,\n",
    "                \"right autochthon\": 105,\n",
    "                \"left iliopsoas\": 106,\n",
    "                \"right iliopsoas\": 107\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def label_id_to_name(self, label_id: int, label_dict: dict):\n",
    "        \"\"\"\n",
    "        Get the label name from the label ID.\n",
    "\n",
    "        Args:\n",
    "            label_id: the label ID.\n",
    "            label_dict: the label dictionary.\n",
    "        \"\"\"\n",
    "        for group_dict in list(label_dict.values()):\n",
    "            if isinstance(group_dict, dict):\n",
    "                # this will skip str type value, such as \"everything\": <path>\n",
    "                for label_name, label_id_ in group_dict.items():\n",
    "                    if label_id == label_id_:\n",
    "                        return label_name\n",
    "        return None\n",
    "\n",
    "    def segmentation_to_string(\n",
    "        self,\n",
    "        output_dir: Path,\n",
    "        img_file: str,\n",
    "        seg_file: str,\n",
    "        label_groups: dict,\n",
    "        modality: str = \"CT\",\n",
    "        slice_index: int | None = None,\n",
    "        axis: int = 2,\n",
    "        image_filename: str = \"image.jpg\",\n",
    "        label_filename: str = \"label.jpg\",\n",
    "        output_prefix=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Format the segmentation response to a string.\n",
    "\n",
    "        Args:\n",
    "            response: the response.\n",
    "            output_dir: the output directory.\n",
    "            img_file: the image file path.\n",
    "            modality: the modality.\n",
    "            slice_index: the slice index.\n",
    "            axis: the axis.\n",
    "            image_filename: the image filename for the sliced image.\n",
    "            label_filename: the label filename for the sliced image.\n",
    "            group_label_names: the group label names to filter the label names.\n",
    "            output_prefix: the output prefix.\n",
    "            label_groups_path: the label groups path for VISTA-3D.\n",
    "        \"\"\"\n",
    "        global SEGMENTATION_TOKEN\n",
    "        output_dir = Path(output_dir)\n",
    "        if output_prefix is None:\n",
    "            output_prefix = f\"The results are {SEGMENTATION_TOKEN}. The colors in this image describe \"\n",
    "\n",
    "        transforms = get_monai_transforms(\n",
    "            [\"image\", \"label\"],\n",
    "            output_dir,\n",
    "            modality=modality,\n",
    "            slice_index=slice_index,\n",
    "            axis=axis,\n",
    "            image_filename=image_filename,\n",
    "            label_filename=label_filename,\n",
    "        )\n",
    "        data = transforms({\"image\": img_file, \"label\": seg_file})\n",
    "\n",
    "        formatted_items = []\n",
    "\n",
    "        for label_id in data[\"colormap\"]:\n",
    "            label_name = self.label_id_to_name(label_id, label_groups)\n",
    "            if label_name is not None:\n",
    "                color = data[\"colormap\"][label_id]\n",
    "                formatted_items.append(f\"{color}: {label_name}\")\n",
    "\n",
    "        return output_prefix + \", \".join(formatted_items) + \". \"\n",
    "\n",
    "    def mentioned_by(self, input: str):\n",
    "        \"\"\"\n",
    "        Check if the VISTA-3D model is mentioned in the input.\n",
    "\n",
    "        Args:\n",
    "            input (str): Text from the LLM, e.g. \"Let me trigger <VISTA3D(arg)>.\"\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the VISTA-3D model is mentioned, False otherwise.\n",
    "        \"\"\"\n",
    "        matches = re.findall(r\"<(.*?)>\", str(input))\n",
    "        if len(matches) != 1:\n",
    "            return False\n",
    "        return self.model_name in str(matches[0])\n",
    "\n",
    "    def download_file(self, url: str, img_file: str):\n",
    "        \"\"\"\n",
    "        Download the file from the URL.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL.\n",
    "            img_file (str): The file path.\n",
    "        \"\"\"\n",
    "        parent_dir = os.path.dirname(img_file)\n",
    "        os.makedirs(parent_dir, exist_ok=True)\n",
    "        with open(img_file, \"wb\") as f:\n",
    "            response = requests.get(url)\n",
    "            f.write(response.content)\n",
    "\n",
    "    def run(\n",
    "        self,\n",
    "        img_file: str = \"\",\n",
    "        image_url: str = \"\",\n",
    "        input: str = \"\",\n",
    "        output_dir: str = \"\",\n",
    "        slice_index: int = 0,\n",
    "        prompt: str = \"\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Run the VISTA-3D model.\n",
    "\n",
    "        Args:\n",
    "            image_url (str): The image URL.\n",
    "            input (str): The input text.\n",
    "            output_dir (str): The output directory.\n",
    "            img_file (str): The image file path. If not provided, download from the URL.\n",
    "            slice_index (int): The slice index.\n",
    "            prompt (str): The prompt text from the original request.\n",
    "            **kwargs: Additional keyword arguments.\n",
    "        \"\"\"\n",
    "        if not img_file:\n",
    "            # Download from the URL\n",
    "            img_file = os.path.join(output_dir, os.path.basename(image_url))\n",
    "            self.download_file(image_url, img_file)\n",
    "\n",
    "        output_dir = Path(output_dir)\n",
    "        matches = re.findall(r\"<(.*?)>\", input)\n",
    "        if len(matches) != 1:\n",
    "            raise ValueError(f\"Expert model {self.model_name} is not correctly enclosed in angle brackets.\")\n",
    "\n",
    "        match = matches[0]\n",
    "\n",
    "        # Extract the arguments\n",
    "        arg_matches = re.findall(r\"\\((.*?)\\)\", match[len(self.model_name) :])\n",
    "\n",
    "        if len(arg_matches) == 0:  # <VISTA3D>\n",
    "            arg_matches = [\"everything\"]\n",
    "        if len(arg_matches) == 1 and (arg_matches[0] == \"\" or arg_matches[0] == None):  # <VISTA3D()>\n",
    "            arg_matches = [\"everything\"]\n",
    "        if len(arg_matches) > 1:\n",
    "            raise ValueError(\n",
    "                \"Multiple expert model arguments are provided in the same prompt, \"\n",
    "                \"which is not supported in this version.\"\n",
    "            )\n",
    "\n",
    "        vista3d_prompts = None\n",
    "        label_groups = self._get_label_groups()\n",
    "\n",
    "        if arg_matches[0] not in label_groups:\n",
    "            raise ValueError(f\"Label group {arg_matches[0]} is not accepted by the VISTA-3D model.\")\n",
    "\n",
    "        if arg_matches[0] != \"everything\":\n",
    "            vista3d_prompts = [cls_idx for _, cls_idx in label_groups[arg_matches[0]].items()]\n",
    "\n",
    "        # Trigger the VISTA-3D model\n",
    "        input_dict = {\"image\": img_file}\n",
    "        if vista3d_prompts is not None:\n",
    "            input_dict[\"label_prompt\"] = vista3d_prompts\n",
    "        else:\n",
    "            input_dict[\"label_prompt\"] = [int(i) for i in range(1, 16)]\n",
    "\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            self.pipeline([input_dict], output_dir=temp_dir)\n",
    "            seg_file = os.path.join(output_dir, \"segmentation.nii.gz\")\n",
    "            temp_output_dir = os.path.join(temp_dir, os.listdir(temp_dir)[0])\n",
    "            output_file = os.path.join(temp_output_dir, os.listdir(temp_output_dir)[0])\n",
    "            if os.path.exists(seg_file):\n",
    "                if os.path.isdir(seg_file):\n",
    "                    from shutil import rmtree\n",
    "                    rmtree(seg_file)\n",
    "                else:\n",
    "                    os.remove(seg_file)\n",
    "            move(output_file, seg_file)\n",
    "            print(f\"File exists: {os.path.exists(seg_file)}\")\n",
    "\n",
    "        seg_image = f\"seg_{uuid4()}.jpg\"\n",
    "        text_output = self.segmentation_to_string(\n",
    "            output_dir,\n",
    "            img_file,\n",
    "            seg_file,\n",
    "            label_groups,\n",
    "            modality=\"CT\",\n",
    "            slice_index=slice_index,\n",
    "            image_filename=get_slice_filenames(img_file, slice_index),\n",
    "            label_filename=seg_image,\n",
    "        )\n",
    "\n",
    "        if \"segmented\" in input:\n",
    "            instruction = \"\"  # no need to ask for instruction\n",
    "        else:\n",
    "            instruction = \"Use this result to respond to this prompt:\\n\" + prompt\n",
    "        return text_output, os.path.join(output_dir, seg_image), instruction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Test the expert VISTA-3D model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-05 09:27:12,946 INFO image_writer.py:197 - writing: /tmp/tmp7h88ipra/ct_liver_0/ct_liver_0_seg.nii.gz\n",
      "File exists: True\n",
      "==================================================test run:==================================================\n",
      "Image segmentation is saved to ../data/seg_4a9d8168-d778-4515-a2b4-639ec1ab10dc.jpg\n",
      "Instruction passed to the follow-up prompt:\n",
      "Use this result to respond to this prompt:\n",
      "Describe the image.\n",
      "Text output:\n",
      "The results are <segmentation>. The colors in this image describe red: liver, blue: spleen, yellow: pancreas, magenta: right kidney, green: aorta, indigo: inferior vena cava, darkorange: right adrenal gland, cyan: left adrenal gland, pink: gallbladder, brown: esophagus, orange: stomach, lime: duodenum, orange: bladder. \n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "expert = ExpertVista3DHF()\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    text_output, seg_image, instruction = expert.run(\n",
    "        img_file=cache_images.get(LIVER_URL),\n",
    "        input=\"Let me trigger <VISTA3D(everything)>.\",\n",
    "        prompt=\"Describe the image.\",\n",
    "        output_dir=\"../data\",\n",
    "        slice_index=0,\n",
    "    )\n",
    "    print(\"=\"*50 + \"test run:\" + \"=\"*50)\n",
    "    print(f\"Image segmentation is saved to {seg_image}\")\n",
    "    print(f\"Instruction passed to the follow-up prompt:\\n{instruction}\")\n",
    "    print(f\"Text output:\\n{text_output}\")\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the expert VISTA-3D model in the VILA-M3 workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-05 09:27:20,508] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 09:27:20 - root - INFO - x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmp_e1iz3l4/test.c -o /tmp/tmp_e1iz3l4/test.o\n",
      "2025-03-05 09:27:20 - root - INFO - x86_64-linux-gnu-gcc /tmp/tmp_e1iz3l4/test.o -laio -o /tmp/tmp_e1iz3l4/a.out\n",
      "/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "2025-03-05 09:27:21 - root - INFO - x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmpkns0prnm/test.c -o /tmp/tmpkns0prnm/test.o\n",
      "2025-03-05 09:27:21 - root - INFO - x86_64-linux-gnu-gcc /tmp/tmpkns0prnm/test.o -L/usr/local/cuda -L/usr/local/cuda/lib64 -lcufile -o /tmp/tmpkns0prnm/a.out\n",
      "2025-03-05 09:27:21 - root - INFO - x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmp82bd4lr6/test.c -o /tmp/tmp82bd4lr6/test.o\n",
      "2025-03-05 09:27:21 - root - INFO - x86_64-linux-gnu-gcc /tmp/tmp82bd4lr6/test.o -laio -o /tmp/tmp82bd4lr6/a.out\n",
      "/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "2025-03-05 09:27:21 - datasets - INFO - PyTorch version 2.3.0 available.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.40s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Model vila_m3_8b loaded successfully. Context length: 2048\n",
      "2025-03-05 09:27:28 - agent_utils - INFO - Model vila_m3_8b loaded successfully. Context length: 2048\n",
      "Processing the prompt: Is there a hepatic tumor in the image, with max tokens: 1024, temperature: 0.0, top P: 0.9, slice index: 57\n",
      "2025-03-05 09:27:28 - agent_utils - INFO - Processing the prompt: Is there a hepatic tumor in the image, with max tokens: 1024, temperature: 0.0, top P: 0.9, slice index: 57\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Expert model ExpertVista3DHF is being called to process https://developer.download.nvidia.com/assets/Clara/monai/samples/ct_liver_0.nii.gz.\n",
      "2025-03-05 09:27:32 - agent_utils - INFO - Expert model ExpertVista3DHF is being called to process https://developer.download.nvidia.com/assets/Clara/monai/samples/ct_liver_0.nii.gz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-05 09:27:35,569 INFO image_writer.py:197 - writing: /tmp/tmp7u6l0pf2/ct_liver_0/ct_liver_0_seg.nii.gz\n",
      "File exists: True\n",
      "====================================================================================================\n",
      "USER: [{'type': 'text', 'text': \"Here is a list of available expert models:\\n<BRATS(args)> Modality: MRI, Task: segmentation, Overview: A pre-trained model for volumetric (3D) segmentation of brain tumor subregions from multimodal MRIs based on BraTS 2018 data, Accuracy: Tumor core (TC): 0.8559 - Whole tumor (WT): 0.9026 - Enhancing tumor (ET): 0.7905 - Average: 0.8518, Valid args are: None\\n<VISTA3D(args)> Modality: CT, Task: segmentation, Overview: domain-specialized interactive foundation model developed for segmenting and annotating human anatomies with precision, Accuracy: 127 organs: 0.792 Dice on average, Valid args are: 'everything', 'hepatic tumor', 'pancreatic tumor', 'lung tumor', 'bone lesion', 'organs', 'cardiovascular', 'gastrointestinal', 'skeleton', or 'muscles'\\n<VISTA2D(args)> Modality: cell imaging, Task: segmentation, Overview: model for cell segmentation, which was trained on a variety of cell imaging outputs, including brightfield, phase-contrast, fluorescence, confocal, or electron microscopy, Accuracy: Good accuracy across several cell imaging datasets, Valid args are: None\\n<CXR(args)> Modality: chest x-ray (CXR), Task: classification, Overview: pre-trained model which are trained on large cohorts of data, Accuracy: Good accuracy across several diverse chest x-rays datasets, Valid args are: None\\nGive the model <NAME(args)> when selecting a suitable expert model.\\n<image>This is a CT image.\\nIs there a hepatic tumor in the image\"}, {'type': 'image_path', 'image_path': '../data/ct_liver_0_slice57_img.jpg'}]\n",
      "ASSISTANT: [{'type': 'text', 'text': 'This looks like a CT image. Let me trigger <VISTA3D(hepatic tumor)>.'}]\n",
      "EXPERT: [{'type': 'text', 'text': 'The results are <segmentation>. The colors in this image describe red: liver. '}, {'type': 'image_path', 'image_path': '/tmp/tmpuwtkssh6/seg_56b9e47b-2168-4a76-9690-738274c432de.jpg'}]\n",
      "EXPERT: [{'type': 'text', 'text': 'Use this result to respond to this prompt:\\nIs there a hepatic tumor in the image'}]\n",
      "ASSISTANT: [{'type': 'text', 'text': 'no.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from agent_utils import SessionVariables, ChatHistory, M3Generator\n",
    "\n",
    "model_path = \"./vila_m3_8b\"\n",
    "sv = SessionVariables()\n",
    "m3 = M3Generator(\n",
    "        cache_images,\n",
    "        source=\"local\",\n",
    "        model_path=model_path,\n",
    "        conv_mode=\"llama_3\",\n",
    "        experts_classes=[ExpertVista3DHF],\n",
    "    )\n",
    "\n",
    "sv.image_url = LIVER_URL\n",
    "sv.slice_index = 57\n",
    "\n",
    "chat_history = ChatHistory()\n",
    "\n",
    "sv, chat_history = m3.process_prompt(\n",
    "    \"Is there a hepatic tumor in the image\",\n",
    "    sv,\n",
    "    chat_history\n",
    ")\n",
    "\n",
    "print(\"=\"*100)\n",
    "\n",
    "for message in chat_history.messages:\n",
    "    role = message[\"role\"].upper()\n",
    "    content = message[\"content\"]\n",
    "    print(f\"{role}: {content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
